{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-25T23:40:08.015962Z","iopub.execute_input":"2023-08-25T23:40:08.017203Z","iopub.status.idle":"2023-08-25T23:40:08.075685Z","shell.execute_reply.started":"2023-08-25T23:40:08.017140Z","shell.execute_reply":"2023-08-25T23:40:08.074369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<img style=\"float:left\" src=\"https://i.imgur.com/DWQOJgU.png\" width=\"1500\">\n\n<h1 style=\"text-alignment:justify\">NYC Citibike Trips</h1>\n<hr>\n24 Aug 2023","metadata":{}},{"cell_type":"markdown","source":"<div>\n<img style=\"float: left\" src=\"https://i.postimg.cc/qvZpHzhk/002-Img-Objectives-Draft-2-20220819.png(https://postimg.cc/cvYpQ1Bj)\" width=\"75\">\n<h2 id=\"Obj1\">Objectives</h2>\n<hr>\n\n<h3 style=\"text-align:justify\">In this project, we will walk through the Data Analytics process, starting from data acquisition and analysis, to gaining business insights and creating models using BigQuery with SQL and Python. The case study will showcase data analyst, business intelligence, and data science analyses to acquire valuable business insights.\n<br><br>\nThe New York Citibike Cyclistic's Customer Growth Team is developing a business plan for the next year (2016). Therefore, the case study will only utilize data from 2014 and 2015. The team's primary objective is to understand how their customers are using their bikes, with a focus on identifying customer demand at different station locations. The key question is: How can we apply customer usage insights to inform new station growth?<br><br>\nAfter part 1 (P01) we have cleaned the data and in part 2 (P02), executed data mining and analysis. Now in part 3 (P03), we will continue creating predictive models on the demand side. The goal of data mining is to gain a deeper understanding of the data and to use this knowledge to make informed decisions, create predictive models, or find valuable patterns and trends for valuable insights. <b>Develop machine learning models that predicts citibike total trip or trip durations based on location and time of day.</b>\n</h3> \n<p style = \"font-family: Arial; font-size: 18px\">Note: This project's dataset was created for pedagogical purposes and may not represent real-world data. The project consists of multiple notebook parts, focusing on combining data from various tables and conducting data analysis and prediction to acquire valuable insights.</p>    \n</div> ","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n<img style=\"float: left\" src=\"https://i.postimg.cc/kXz8cFqC/005-Img-Yellow-Notes-Draft-1-20220819.png\" width=\"60\">\n<b style = \"font-family: Arial; font-size: 16px\">Remember:</b><p style = \"font-family:Verdana; font-size:14px\">We must be <b>objective</b> in analyzing the data in order to acquire valuable insights and understand it by collecting, fact checking or challenging the data and other sources. Go to where the data - Genchi Genbutsu attitudes. Data must be <b>Clear, Objective, Valuable, Focus, Agile, Scientific and Timeframe (COV-FAST)</b></p>\n    <p style = \"font-family:Verdana; font-size:14px\">There are other methodologies may be considered like, logistic regression, random forest or neural networking. We can use the same preprocessing dataset and try each options methodologies in seperate notebooks</p>\n</div>\n    <h3>Methodologies Overview</h3>\n<h3>Data Analysis PACE Steps:</h3>\n   <ol style=\"font-family:Verdana; font-size:16px\">\n    <li><img style=\"float:left\" src=\"https://i.imgur.com/gIne5bH.png\" width=\"50\"> Define (Plan & Analyze - EDA) - PART 1</li> \n    <blockquote>\n    <ol>Understand your data in the problem context\n        <br>EDA - check model, assumption & select model\n    </ol>\n    </blockquote>\n        <li><img style=\"float:left\" src=\"https://i.imgur.com/rb8V6X5.png\" width=\"50\">Measure (Analyze - EDA)</li>\n    <blockquote>\n    <ol> EDA - check model, assumption & select model\n     </ol>\n    </blockquote>\n    <li><img style=\"float:left\" src=\"https://i.imgur.com/J4M3HKM.png\" width=\"50\">Analyze (Construct) </li>\n    <blockquote>\n    <ol>Contruct and evaluate model\n     </ol>\n    </blockquote>\n    <li><img style=\"float:left\" src=\"https://i.imgur.com/wpcEXQC.png\" width=\"50\">Improve (Execute) - interpret model and share the story</li>\n    <br>\n    <li>Control</li>   ","metadata":{}},{"cell_type":"markdown","source":"# Methodologies Overview\n<hr>\n\n<h3 style = \"text-align:center\">Table 1.1. DMAIC vs Data Analytics Methodologies (Define)</h3>\n<table style=\"color:black;\n           display:fill;\n           border-colapse: colapse;\n           width: 100%;\n           border: 1px solid black;\n           border-collapse: collapse;\n           border-style: solid;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n  <tr>\n    <th colspan=\"5\">Six Sigma DMAIC 12 Steps</th>\n  </tr>\n    \n  <tr>\n        <th colspan=\"2\"><em>Define</em></th>\n    <th colspan=\"3\">Customer expectations of the process? </th>\n  </tr>\n    \n  <tr>\n    <th>Steps</th>\n    <th>Description</th>\n    <th>Focus</th>\n    <th>Tools</th>\n    <th>Timeline</th>\n  </tr>\n    \n  <tr>\n    <td style =\"text-align:left\" >A\n      </td>\n    <td>Identify Project's CTQ</td>\n    <td style = \"text-align:center\">      \n      Y \n    </td>\n    <td style =\"text-align:left\">\n      CTQ drill down tree, \n        VOC, Pareto, Bar Chart \n    </td>\n      <td style =\"text-align:center\">\n      3 - 5 days \n    </td>\n  </tr>\n    \n  <tr>\n    <td style =\"text-align:left\" >B\n      </td>\n    <td>Define Process Mapping</td>\n    <td style = \"text-align:center\">      \n     Y\n    </td>\n    <td style =\"text-align:left\">\n     SIPOC\n    </td>\n    <td style =\"text-align:center\">\n      3 - 5 days \n    </td>\n  </tr>\n    \n  <tr>\n    <td style =\"text-align:left\" >C\n      </td>\n    <td>Establish The Team's Charter</td>\n    <td style = \"text-align:center\">      \n     Y\n    </td>\n    <td style =\"text-align:left\">\n     Milestones, Team Members, Stakeholders, Project Charter \n    </td>\n    <td style =\"text-align:center\">\n      3 - 5 days \n    </td>\n  </tr>\n    \n<tr style = \"border-top: solid \">\n    <th colspan=\"5\">Data Analytics 6 Steps - Project Initiation and Planning Phase</th>\n  </tr>\n    \n <tr>\n        <th colspan=\"2\"><em>Ask and Prepare</em></th>\n    <th colspan=\"3\">Customer expectations of the process? </th>\n </tr>\n    \n  <tr>\n    <th>Steps</th>\n    <th>Description</th>\n    <th>Focus</th>\n    <th>Tools</th>\n    <th>Timeline</th>\n  </tr>\n    \n  <tr>\n    <td style =\"text-align:left\" >Ask - Mining\n      </td>\n    <td>A Clear Statement of The Business Task</td>\n    <td style = \"text-align:center\">      \n      Y \n    </td>\n    <td style =\"text-align:left\">\n      CTQ drill down tree, \n        VOC, Pareto, Bar Chart  \n    </td>\n    <td style =\"text-align:center\">\n      3 - 5 days \n    </td>\n  </tr>\n    \n  <tr>\n    <td style =\"text-align:left\" >Ask - Mining\n      </td>\n    <td>Mapping Key Stakholders</td>\n    <td style = \"text-align:center\">      \n     Y\n    </td>\n    <td style =\"text-align:left\">\n     RACI Matrix\n    </td>\n    <td style =\"text-align:center\">\n      3 - 5 days \n    </td>\n  </tr>\n    \n  <tr>\n    <td style =\"text-align:left\" >Prepare\n      </td>\n    <td>A Description of All Data Used</td>\n    <td style = \"text-align:center\">      \n     Y\n    </td>\n    <td style =\"text-align:left\">\n     Data Preparation or Mining \n    </td>\n    <td style =\"text-align:center\">\n      3 - 5 days \n    </td>\n  </tr>\n    \n </table>","metadata":{}},{"cell_type":"markdown","source":"<img style=\"float:left\" src=\"https://i.imgur.com/gIne5bH.png\" width=\"80\">\n\n# Import the relevant libraries","metadata":{}},{"cell_type":"code","source":"# For data visualization\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# For displaying all of the columns in dataframes\npd.set_option('display.max_columns', None)\n\n# For data modeling\nfrom xgboost import XGBClassifier\nfrom xgboost import XGBRegressor\nfrom xgboost import plot_importance\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# For metrics and helpful functions\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score,\\\nf1_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.tree import plot_tree\n\n# For saving models\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:41:14.651382Z","iopub.execute_input":"2023-08-25T23:41:14.651795Z","iopub.status.idle":"2023-08-25T23:41:16.458533Z","shell.execute_reply.started":"2023-08-25T23:41:14.651763Z","shell.execute_reply":"2023-08-25T23:41:16.457103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing\n### Load the data","metadata":{}},{"cell_type":"code","source":"raw_data=pd.read_csv('/kaggle/input/proj005-p03-nyc-ds-citibike-202308024/nyc_citibike_trip_2014_2015_20230801_v2.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:41:18.238245Z","iopub.execute_input":"2023-08-25T23:41:18.238706Z","iopub.status.idle":"2023-08-25T23:41:22.373499Z","shell.execute_reply.started":"2023-08-25T23:41:18.238668Z","shell.execute_reply":"2023-08-25T23:41:22.372507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = raw_data.copy()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:41:22.376366Z","iopub.execute_input":"2023-08-25T23:41:22.377200Z","iopub.status.idle":"2023-08-25T23:41:22.543334Z","shell.execute_reply.started":"2023-08-25T23:41:22.377138Z","shell.execute_reply":"2023-08-25T23:41:22.541791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:41:22.545089Z","iopub.execute_input":"2023-08-25T23:41:22.545517Z","iopub.status.idle":"2023-08-25T23:41:22.587479Z","shell.execute_reply.started":"2023-08-25T23:41:22.545479Z","shell.execute_reply":"2023-08-25T23:41:22.586217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set(style='whitegrid')","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:41:22.590350Z","iopub.execute_input":"2023-08-25T23:41:22.590716Z","iopub.status.idle":"2023-08-25T23:41:22.601748Z","shell.execute_reply.started":"2023-08-25T23:41:22.590669Z","shell.execute_reply":"2023-08-25T23:41:22.600389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(df.isna(), yticklabels=False,cbar=False,cmap='viridis')","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:41:22.603259Z","iopub.execute_input":"2023-08-25T23:41:22.603744Z","iopub.status.idle":"2023-08-25T23:42:06.143845Z","shell.execute_reply.started":"2023-08-25T23:41:22.603697Z","shell.execute_reply":"2023-08-25T23:42:06.142613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.duplicated().mean()*100","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:42:06.145647Z","iopub.execute_input":"2023-08-25T23:42:06.146353Z","iopub.status.idle":"2023-08-25T23:42:06.834762Z","shell.execute_reply.started":"2023-08-25T23:42:06.146302Z","shell.execute_reply":"2023-08-25T23:42:06.833625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find duplicate rows\nduplicates = df[df.duplicated()]\nduplicates","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:42:06.836691Z","iopub.execute_input":"2023-08-25T23:42:06.837145Z","iopub.status.idle":"2023-08-25T23:42:07.509875Z","shell.execute_reply.started":"2023-08-25T23:42:06.837102Z","shell.execute_reply":"2023-08-25T23:42:07.508596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop duplicate rows\ndf = df.drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:42:07.511257Z","iopub.execute_input":"2023-08-25T23:42:07.511669Z","iopub.status.idle":"2023-08-25T23:42:08.244347Z","shell.execute_reply.started":"2023-08-25T23:42:07.511636Z","shell.execute_reply":"2023-08-25T23:42:08.242974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 1: Logistic Regression (1)\n\n<div class=\"alert alert-block alert-warning\">\n<img style=\"float: left\" src=\"https://i.postimg.cc/kXz8cFqC/005-Img-Yellow-Notes-Draft-1-20220819.png\" width=\"60\">\n<b style = \"font-family: Arial; font-size: 16px\">Notes:</b><p style = \"font-family:Verdana; font-size:14px\"> <b>Logistic regression is quite sensitive to outliers.\n</div>","metadata":{}},{"cell_type":"markdown","source":"### Dependent and independent variables","metadata":{}},{"cell_type":"code","source":"# Set Y variable\ny=df['user_type']\n\n# Remove the target column from the features\nX = df.drop(columns=\"user_type\")\n\n# Display first few rows\nX.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:42:08.245804Z","iopub.execute_input":"2023-08-25T23:42:08.246170Z","iopub.status.idle":"2023-08-25T23:42:08.456289Z","shell.execute_reply.started":"2023-08-25T23:42:08.246137Z","shell.execute_reply":"2023-08-25T23:42:08.455028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training model","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:42:08.460388Z","iopub.execute_input":"2023-08-25T23:42:08.460788Z","iopub.status.idle":"2023-08-25T23:42:08.793811Z","shell.execute_reply.started":"2023-08-25T23:42:08.460757Z","shell.execute_reply":"2023-08-25T23:42:08.792565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = LogisticRegression()\nclf = clf.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:42:08.795626Z","iopub.execute_input":"2023-08-25T23:42:08.796006Z","iopub.status.idle":"2023-08-25T23:42:14.327910Z","shell.execute_reply.started":"2023-08-25T23:42:08.795973Z","shell.execute_reply":"2023-08-25T23:42:14.326718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Parameter estimates","metadata":{}},{"cell_type":"code","source":"clf.coef_","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:42:14.329451Z","iopub.execute_input":"2023-08-25T23:42:14.338662Z","iopub.status.idle":"2023-08-25T23:42:14.366204Z","shell.execute_reply.started":"2023-08-25T23:42:14.338566Z","shell.execute_reply":"2023-08-25T23:42:14.364391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.intercept_","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:42:14.375775Z","iopub.execute_input":"2023-08-25T23:42:14.381020Z","iopub.status.idle":"2023-08-25T23:42:14.399812Z","shell.execute_reply.started":"2023-08-25T23:42:14.380928Z","shell.execute_reply":"2023-08-25T23:42:14.397813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction and evaluation","metadata":{}},{"cell_type":"code","source":"y_pred = clf.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:42:14.408905Z","iopub.execute_input":"2023-08-25T23:42:14.410426Z","iopub.status.idle":"2023-08-25T23:42:14.476105Z","shell.execute_reply.started":"2023-08-25T23:42:14.410347Z","shell.execute_reply":"2023-08-25T23:42:14.473610Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Confusion matrix","metadata":{}},{"cell_type":"code","source":"# Compute values for confusion matrix\nlog_cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\n\n# Create display of confusion matrix\nlog_disp = ConfusionMatrixDisplay(confusion_matrix=log_cm, display_labels=clf.classes_)\n\n# Plot confusion matrix\nlog_disp.plot()\n\n# Display plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:42:14.484572Z","iopub.execute_input":"2023-08-25T23:42:14.490361Z","iopub.status.idle":"2023-08-25T23:42:14.880063Z","shell.execute_reply.started":"2023-08-25T23:42:14.490246Z","shell.execute_reply":"2023-08-25T23:42:14.878643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['user_type'].value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:42:14.881502Z","iopub.execute_input":"2023-08-25T23:42:14.881940Z","iopub.status.idle":"2023-08-25T23:42:14.895888Z","shell.execute_reply.started":"2023-08-25T23:42:14.881905Z","shell.execute_reply":"2023-08-25T23:42:14.894609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create classification report for logistic regression model\ntarget_names = ['Predicted annual member', 'Predicted per ride']\nroc_auc = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\nprint(classification_report(y_test, y_pred, target_names=target_names))\nprint(confusion_matrix(y_test,y_pred))\nprint('\\n')\nprint(accuracy_score(y_test,y_pred))\nprint(f'ROC AUC: {roc_auc:.2f}')","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:42:14.898105Z","iopub.execute_input":"2023-08-25T23:42:14.898553Z","iopub.status.idle":"2023-08-25T23:42:15.097673Z","shell.execute_reply.started":"2023-08-25T23:42:14.898502Z","shell.execute_reply":"2023-08-25T23:42:15.096370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n<img style=\"float: left\" src=\"https://i.postimg.cc/kXz8cFqC/005-Img-Yellow-Notes-Draft-1-20220819.png\" width=\"60\">\n<b style = \"font-family: Arial; font-size: 16px\">Notes:</b><p style = \"font-family:Verdana; font-size:14px\"> Having precision, recall, and F1-score of 100% might seem ideal, but it can also be a sign of a potential issue or overfitting, especially if you're dealing with imbalanced classes or if the model is not being tested on unseen data. While high scores are desirable, it's important to thoroughly evaluate the model's performance on a larger dataset, cross-validation, and potentially on an independent test set to ensure that the model generalizes well and isn't overfitting to the training data.</p>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<img style=\"float: left\" src=\"https://i.imgur.com/HVpiyd6.png[/img\" width=\"60\">\n<b style = \"font-family: Arial; font-size: 16px\">Results:</b><p style = \"font-family:Verdana; font-size:14px\">The classification report above shows that the logistic regression model achieved a precision of 100%, recall of 100%, f1-score of 100% (all weighted averages), and accuracy of 99.98%. A precision of 100% means that all the positive predictions made by the model were correct. A recall (sensitivity) of 100% means that the model correctly identified all positive instances in the dataset. A high F1-score indicates that the model has a good balance between precision and recall. An accuracy of 99.98% means that the model's predictions were correct for 99.98% of the instances.\n    </p> ","metadata":{}},{"cell_type":"markdown","source":"### Handling imbalanced data (the Synthetic Minority Over-sampling Technique (SMOTE))","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import balanced_accuracy_score","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:42:15.099447Z","iopub.execute_input":"2023-08-25T23:42:15.100490Z","iopub.status.idle":"2023-08-25T23:42:15.330670Z","shell.execute_reply.started":"2023-08-25T23:42:15.100435Z","shell.execute_reply":"2023-08-25T23:42:15.329405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Apply SMOTE to balance the target variable\nsmote = SMOTE(random_state=42)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\n# Train a regression model\nclf = LogisticRegression()\nclf = clf.fit(X_train,y_train)\n\n# Make predictions on the test set\ny_pred = clf.predict(X_test)\n\n# Calculate the balanced accuracy score\nbalanced_acc = balanced_accuracy_score(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse:.2f}\")\nprint(f\"Balanced Accuracy: {balanced_acc:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:42:15.332529Z","iopub.execute_input":"2023-08-25T23:42:15.332906Z","iopub.status.idle":"2023-08-25T23:42:25.670849Z","shell.execute_reply.started":"2023-08-25T23:42:15.332874Z","shell.execute_reply":"2023-08-25T23:42:25.669181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cross validation","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:42:25.673129Z","iopub.execute_input":"2023-08-25T23:42:25.684840Z","iopub.status.idle":"2023-08-25T23:42:25.697703Z","shell.execute_reply.started":"2023-08-25T23:42:25.684748Z","shell.execute_reply":"2023-08-25T23:42:25.695873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize the Logistic Regression model\nmodel = LogisticRegression()\n\n# Perform cross-validation and calculate metrics\ncv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\nmean_cv_accuracy = np.mean(cv_scores)\n\n# Train the model on the full training set\nmodel.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = model.predict(X_test)\n\n# Calculate evaluation metrics\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nroc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n\n# Print the results\n# Create classification report for logistic regression model\ntarget_names = ['Predicted annual member', 'Predicted per ride']\nroc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\nprint(classification_report(y_test, y_pred, target_names=target_names))\nprint(confusion_matrix(y_test,y_pred))\nprint('\\n')\nprint(accuracy_score(y_test,y_pred))\nprint(f'Mean Cross-Validation Accuracy: {mean_cv_accuracy:.2f}')\nprint(f'ROC AUC: {roc_auc:.2f}')","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:42:25.700166Z","iopub.execute_input":"2023-08-25T23:42:25.701137Z","iopub.status.idle":"2023-08-25T23:42:57.237152Z","shell.execute_reply.started":"2023-08-25T23:42:25.701072Z","shell.execute_reply":"2023-08-25T23:42:57.235751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n<img style=\"float: left\" src=\"https://i.postimg.cc/kXz8cFqC/005-Img-Yellow-Notes-Draft-1-20220819.png\" width=\"60\">\n<b style = \"font-family: Arial; font-size: 16px\">Notes:</b><p style = \"font-family:Verdana; font-size:14px\">While achieving these perfect scores might seem desirable, it's crucial to be skeptical and consider potential issues like overfitting or data leakage. It's always a good practice to evaluate a model using a variety of metrics and to use techniques like cross-validation to ensure its robustness on new data.</p>\n</div>","metadata":{}},{"cell_type":"code","source":"# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create a Logistic Regression model with L2 regularization (Ridge)\nlogreg = LogisticRegression(penalty='l2', C=1.0, random_state=42)\n\n# Fit the model on the training data\nlogreg.fit(X_train, y_train)\n\n# Make predictions on the test data\ny_pred = logreg.predict(X_test)\n\n# Evaluate the model\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:42:57.239141Z","iopub.execute_input":"2023-08-25T23:42:57.240246Z","iopub.status.idle":"2023-08-25T23:43:04.338573Z","shell.execute_reply.started":"2023-08-25T23:42:57.240204Z","shell.execute_reply":"2023-08-25T23:43:04.337367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Save model","metadata":{}},{"cell_type":"code","source":"import math\n#Taking different set of values for C where C = 1/λ\nparameters={'C':[10**-6,10**-5,10**-4, 10**-2, 10**0, 10**2, 10**3]}\n\n#For plotting\nlog_c = list(map(lambda x : float(math.log(x)),parameters['C']))\n\n#Using sklearn's LogisticRegression classifier with L2- norm\nclf_log = LogisticRegression(penalty='l2') \n\n#Hyperparameter tuning with 5 fold CV using grid search\nclf_2 = GridSearchCV(clf_log, parameters, cv=5,scoring='neg_log_loss',return_train_score =True)\nclf_2.fit(X_train, y_train)\n\ntrain_loss= clf_2.cv_results_['mean_train_score']\ncv_loss = clf_2.cv_results_['mean_test_score'] \n#A function defined for plotting cv and trian errors \n#plt.errors(k=log_c,train=train_loss,cv=cv_loss)\nplt.plot(log_c, train_loss, color=\"blue\",  label=\"Training loss\")\nplt.plot(log_c, cv_loss, color=\"red\",  label=\"Cv loss\")\nplt.legend(loc=\"best\")","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:43:04.340519Z","iopub.execute_input":"2023-08-25T23:43:04.341658Z","iopub.status.idle":"2023-08-25T23:45:47.767947Z","shell.execute_reply.started":"2023-08-25T23:43:04.341611Z","shell.execute_reply":"2023-08-25T23:45:47.766753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf_2 = clf_2.best_estimator_\n#Trainig the model with the best value of C\nclf_2.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:45:47.769530Z","iopub.execute_input":"2023-08-25T23:45:47.769883Z","iopub.status.idle":"2023-08-25T23:45:53.430389Z","shell.execute_reply.started":"2023-08-25T23:45:47.769848Z","shell.execute_reply":"2023-08-25T23:45:53.429176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_fpr, train_tpr, thresholds = roc_curve(y_train,clf_2.predict_proba(X_train)[:,1]) #false positive rate, true positive rate, clf= classifier\ntest_fpr, test_tpr, thresholds = roc_curve(y_test, clf_2.predict_proba(X_test)[:,1]) ","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:45:53.432495Z","iopub.execute_input":"2023-08-25T23:45:53.433402Z","iopub.status.idle":"2023-08-25T23:45:53.745379Z","shell.execute_reply.started":"2023-08-25T23:45:53.433355Z","shell.execute_reply":"2023-08-25T23:45:53.743738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nauc = roc_curve(y_test, clf_2.predict_proba(X_test)[:,1])\nauc_train = round(metrics.auc(train_fpr, train_tpr),2)\nauc_test = round(metrics.auc(test_fpr, test_tpr),2)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:45:53.756430Z","iopub.execute_input":"2023-08-25T23:45:53.757707Z","iopub.status.idle":"2023-08-25T23:45:53.845243Z","shell.execute_reply.started":"2023-08-25T23:45:53.757655Z","shell.execute_reply":"2023-08-25T23:45:53.843566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting AUC  \n\nplt.plot(train_fpr, train_tpr, label=\"train AUC= \"+ str(auc_train)) \nplt.plot(test_fpr, test_tpr, label=\"test AUC= \"+ str(auc_test)) \nplt.legend() \nplt.xlabel(\"FPR\") \nplt.ylabel(\"TPR\") \nplt.title(\"ROC for Train and Test data with best_fit\") \nplt.grid()\nplt.savefig('ROC-logreg1.png', dpi=100, bbox_inches = \"tight\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:45:53.847610Z","iopub.execute_input":"2023-08-25T23:45:53.848503Z","iopub.status.idle":"2023-08-25T23:45:54.682928Z","shell.execute_reply.started":"2023-08-25T23:45:53.848456Z","shell.execute_reply":"2023-08-25T23:45:54.681590Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"independent_var = df.drop('user_type',axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:45:54.684256Z","iopub.execute_input":"2023-08-25T23:45:54.684669Z","iopub.status.idle":"2023-08-25T23:45:54.809183Z","shell.execute_reply.started":"2023-08-25T23:45:54.684637Z","shell.execute_reply":"2023-08-25T23:45:54.808238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"independent_var.columns.values","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:45:54.810802Z","iopub.execute_input":"2023-08-25T23:45:54.811458Z","iopub.status.idle":"2023-08-25T23:45:54.828500Z","shell.execute_reply.started":"2023-08-25T23:45:54.811422Z","shell.execute_reply":"2023-08-25T23:45:54.827330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_name = independent_var.columns.values","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:45:54.830640Z","iopub.execute_input":"2023-08-25T23:45:54.831222Z","iopub.status.idle":"2023-08-25T23:45:54.841224Z","shell.execute_reply.started":"2023-08-25T23:45:54.831178Z","shell.execute_reply":"2023-08-25T23:45:54.839939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary_table = pd.DataFrame(columns=['Feature Name'], data = feature_name)\nsummary_table['Coefficient'] = np.transpose(clf.coef_)\n\nsummary_table","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:45:54.842928Z","iopub.execute_input":"2023-08-25T23:45:54.843364Z","iopub.status.idle":"2023-08-25T23:45:54.865584Z","shell.execute_reply.started":"2023-08-25T23:45:54.843329Z","shell.execute_reply":"2023-08-25T23:45:54.864405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary_table.index = summary_table.index + 1\n\nsummary_table.loc[0] = ['Intercept', clf.intercept_[0]]\nsummary_table = summary_table.sort_index()\nsummary_table","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:45:54.867155Z","iopub.execute_input":"2023-08-25T23:45:54.867567Z","iopub.status.idle":"2023-08-25T23:45:54.889439Z","shell.execute_reply.started":"2023-08-25T23:45:54.867532Z","shell.execute_reply":"2023-08-25T23:45:54.888016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Interpreting the coefficient","metadata":{}},{"cell_type":"code","source":"summary_table['Odds_ratio'] = np.exp(summary_table.Coefficient)\nsummary_table","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:45:54.891154Z","iopub.execute_input":"2023-08-25T23:45:54.891655Z","iopub.status.idle":"2023-08-25T23:45:54.909612Z","shell.execute_reply.started":"2023-08-25T23:45:54.891611Z","shell.execute_reply":"2023-08-25T23:45:54.908334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary_table_1 = summary_table.drop([0],axis=0)\nsummary_table_1 = summary_table_1[(summary_table_1['Odds_ratio']>1)&(summary_table_1['Coefficient']>0)].sort_values('Odds_ratio', ascending = False)\nsummary_table_1","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:45:54.911286Z","iopub.execute_input":"2023-08-25T23:45:54.911759Z","iopub.status.idle":"2023-08-25T23:45:54.935529Z","shell.execute_reply.started":"2023-08-25T23:45:54.911706Z","shell.execute_reply":"2023-08-25T23:45:54.934252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"blankIndex=[''] * len(summary_table_1)\nsummary_table_1.index=blankIndex\nsummary_table_1","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:45:54.937568Z","iopub.execute_input":"2023-08-25T23:45:54.938138Z","iopub.status.idle":"2023-08-25T23:45:54.955477Z","shell.execute_reply.started":"2023-08-25T23:45:54.938093Z","shell.execute_reply":"2023-08-25T23:45:54.954155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary_table_2 = summary_table.drop([0],axis=0)\nsummary_table_2 = summary_table_1[(summary_table_1['Odds_ratio']>1)&(summary_table_1['Coefficient']>0.5)].sort_values('Odds_ratio', ascending = False)\nsummary_table_2","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:45:54.956770Z","iopub.execute_input":"2023-08-25T23:45:54.957142Z","iopub.status.idle":"2023-08-25T23:45:54.980534Z","shell.execute_reply.started":"2023-08-25T23:45:54.957100Z","shell.execute_reply":"2023-08-25T23:45:54.979188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ticks=np.arange(19)\nlabels=summary_table_2['Feature Name']","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:45:54.982461Z","iopub.execute_input":"2023-08-25T23:45:54.983254Z","iopub.status.idle":"2023-08-25T23:45:54.988275Z","shell.execute_reply.started":"2023-08-25T23:45:54.983218Z","shell.execute_reply":"2023-08-25T23:45:54.986898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 10))  # Increase the figure size\nsummary_table_1.sort_values('Odds_ratio', ascending=False).plot(kind='bar')\nplt.xticks(ticks, labels, rotation='vertical', fontsize=10)  # Increase font size\nplt.subplots_adjust(bottom=0.05)  # Adjust the bottom margin to make room for x-labels\nplt.tight_layout()  # Adjust the layout\nplt.savefig('log_reg1.png', dpi=100, bbox_inches='tight')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:45:54.989457Z","iopub.execute_input":"2023-08-25T23:45:54.990275Z","iopub.status.idle":"2023-08-25T23:45:57.112359Z","shell.execute_reply.started":"2023-08-25T23:45:54.990231Z","shell.execute_reply":"2023-08-25T23:45:57.110960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.kdeplot(x='Odds_ratio', y='Coefficient', data=summary_table_1, logistic=True, ci=None)\nplt.title('Odds ratio vs coefficient')\nplt.savefig('odds-ratio-logreg1.png', dpi=100, bbox_inches = \"tight\")","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:45:57.114016Z","iopub.execute_input":"2023-08-25T23:45:57.114387Z","iopub.status.idle":"2023-08-25T23:45:57.942644Z","shell.execute_reply.started":"2023-08-25T23:45:57.114353Z","shell.execute_reply":"2023-08-25T23:45:57.941224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n<img style=\"float: left\" src=\"https://i.postimg.cc/kXz8cFqC/005-Img-Yellow-Notes-Draft-1-20220819.png\" width=\"60\">\n<b style = \"font-family: Arial; font-size: 16px\">Notes:</b><p style = \"font-family:Verdana; font-size:14px\">While achieving these perfect scores might seem desirable, it's crucial to be skeptical and consider potential issues like overfitting or data leakage. It's always a good practice to evaluate a model using a variety of metrics and to use techniques like cross-validation to ensure its robustness on new data.<b> Using ensemble methods like Random Forest or Gradient Boosting, which combine multiple weak learners to create a stronger model. These methods tend to generalize well and are less prone to overfitting.</b></p>\n</div>","metadata":{}},{"cell_type":"markdown","source":"###  Scaled data","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:49:41.330237Z","iopub.execute_input":"2023-08-25T23:49:41.330777Z","iopub.status.idle":"2023-08-25T23:49:41.336115Z","shell.execute_reply.started":"2023-08-25T23:49:41.330740Z","shell.execute_reply":"2023-08-25T23:49:41.334949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:49:43.482483Z","iopub.execute_input":"2023-08-25T23:49:43.482893Z","iopub.status.idle":"2023-08-25T23:49:44.217683Z","shell.execute_reply.started":"2023-08-25T23:49:43.482860Z","shell.execute_reply":"2023-08-25T23:49:44.216441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply SMOTE to the training data\nsmote = SMOTE(random_state=42)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:49:45.964540Z","iopub.execute_input":"2023-08-25T23:49:45.964975Z","iopub.status.idle":"2023-08-25T23:49:48.507828Z","shell.execute_reply.started":"2023-08-25T23:49:45.964942Z","shell.execute_reply":"2023-08-25T23:49:48.506632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train a logistic regression model on the resampled data\nmodel = LogisticRegression()\nmodel.fit(X_train_resampled, y_train_resampled)\n\n# Predict on test data\ny_pred = model.predict(X_test_scaled)\n\n# Evaluate the model\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-08-25T23:49:48.509896Z","iopub.execute_input":"2023-08-25T23:49:48.510391Z","iopub.status.idle":"2023-08-25T23:49:58.726661Z","shell.execute_reply.started":"2023-08-25T23:49:48.510352Z","shell.execute_reply":"2023-08-25T23:49:58.725501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n<img style=\"float: left\" src=\"https://i.postimg.cc/kXz8cFqC/005-Img-Yellow-Notes-Draft-1-20220819.png\" width=\"60\">\n<b style = \"font-family: Arial; font-size: 16px\">Note:</b><ol style = \"font-family:Verdana; font-size:14px\">\n<ul>Benefits of using StandardScaler:\n<li>Helps algorithms that rely on distance metrics or gradient-based optimization converge faster.\n<li>Prevents features with larger scales from dominating the learning process.\n<li>Makes the data more suitable for algorithms like Support Vector Machines (SVM), K-Means clustering, and Principal Component Analysis (PCA).</ul><br>\nKeep in mind that some algorithms, like tree-based models (e.g., decision trees, random forests), are less sensitive to feature scaling and may not require StandardScaler. However, for algorithms like linear regression, logistic regression, and k-nearest neighbors, standardizing features can have a significant impact on their performance and convergence.\n</div>","metadata":{}},{"cell_type":"markdown","source":"# Model 2: Decision Tree (1)","metadata":{}},{"cell_type":"code","source":"#Encode the categorical variables\ndf_1 = df.copy()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T06:29:15.827478Z","iopub.execute_input":"2023-08-25T06:29:15.827963Z","iopub.status.idle":"2023-08-25T06:29:15.995174Z","shell.execute_reply.started":"2023-08-25T06:29:15.827923Z","shell.execute_reply":"2023-08-25T06:29:15.993866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split, Train and Test Data","metadata":{}},{"cell_type":"code","source":"# Isolate the outcome variable\ny = df_1['user_type']\n# Select the features\nX = df_1.drop('user_type', axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T06:29:16.882133Z","iopub.execute_input":"2023-08-25T06:29:16.883132Z","iopub.status.idle":"2023-08-25T06:29:17.021206Z","shell.execute_reply.started":"2023-08-25T06:29:16.883089Z","shell.execute_reply":"2023-08-25T06:29:17.019544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Training model","metadata":{}},{"cell_type":"code","source":"# Create test data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\n# Create train & validate data\nX_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.25, stratify=y_train, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T06:29:17.580120Z","iopub.execute_input":"2023-08-25T06:29:17.580535Z","iopub.status.idle":"2023-08-25T06:29:18.358402Z","shell.execute_reply.started":"2023-08-25T06:29:17.580502Z","shell.execute_reply":"2023-08-25T06:29:18.356690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiate model\ntree = DecisionTreeClassifier(random_state=42)\n\n# Assign a dictionary of hyperparameters to search over\ncv_params = {'max_depth':[3, 6, 9, None],\n             'min_samples_leaf': [3, 5, 7],\n             'min_samples_split': [3, 4, 5]\n             }\n\n# Assign a dictionary of scoring metrics to capture\nscoring = {'accuracy', 'precision', 'recall', 'f1', 'roc_auc'}\n\n# Instantiate GridSearch\ntree1 = GridSearchCV(tree, cv_params, scoring=scoring, cv=4, refit='roc_auc')","metadata":{"execution":{"iopub.status.busy":"2023-08-25T06:29:18.361241Z","iopub.execute_input":"2023-08-25T06:29:18.361756Z","iopub.status.idle":"2023-08-25T06:29:18.370896Z","shell.execute_reply.started":"2023-08-25T06:29:18.361710Z","shell.execute_reply":"2023-08-25T06:29:18.369087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntree1.fit(X_train, y_train) #~1:24s","metadata":{"execution":{"iopub.status.busy":"2023-08-25T06:29:19.257176Z","iopub.execute_input":"2023-08-25T06:29:19.257615Z","iopub.status.idle":"2023-08-25T06:31:07.090732Z","shell.execute_reply.started":"2023-08-25T06:29:19.257580Z","shell.execute_reply":"2023-08-25T06:31:07.089411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check best AUC score on CV\ntree1.best_score_","metadata":{"execution":{"iopub.status.busy":"2023-08-25T06:31:07.093221Z","iopub.execute_input":"2023-08-25T06:31:07.094395Z","iopub.status.idle":"2023-08-25T06:31:07.102954Z","shell.execute_reply.started":"2023-08-25T06:31:07.094344Z","shell.execute_reply":"2023-08-25T06:31:07.101334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_results(model_name:str, model_object, metric:str):\n    '''\n    Arguments:\n        model_name (string): what you want the model to be called in the output table\n        model_object: a fit GridSearchCV object\n        metric (string): precision, recall, f1, accuracy, or auc\n  \n    Returns a pandas df with the F1, recall, precision, accuracy, and auc scores\n    for the model with the best mean 'metric' score across all validation folds.  \n    '''\n\n    # Create dictionary that maps input metric to actual metric name in GridSearchCV\n    metric_dict = {'auc': 'mean_test_roc_auc',\n                 'precision': 'mean_test_precision',\n                 'recall': 'mean_test_recall',\n                 'f1': 'mean_test_f1',\n                 'accuracy': 'mean_test_accuracy',\n                 }\n\n    # Get all the results from the CV and put them in a df\n    cv_results = pd.DataFrame(model_object.cv_results_)\n\n    # Isolate the row of the df with the max(metric) score\n    best_estimator_results = cv_results.iloc[cv_results[metric_dict[metric]].idxmax(), :]\n\n    # Extract Accuracy, precision, recall, and f1 score from that row\n    auc = best_estimator_results.mean_test_roc_auc\n    f1 = best_estimator_results.mean_test_f1\n    recall = best_estimator_results.mean_test_recall\n    precision = best_estimator_results.mean_test_precision\n    accuracy = best_estimator_results.mean_test_accuracy\n  \n    # Create table of results\n    table = pd.DataFrame()\n    table = table.append({'Model': model_name,\n                        'AUC': auc,\n                        'Precision': precision,\n                        'Recall': recall,\n                        'F1': f1,\n                        'Accuracy': accuracy,\n                        },\n                        ignore_index=True\n                       )\n  \n    return table","metadata":{"execution":{"iopub.status.busy":"2023-08-25T06:31:07.105165Z","iopub.execute_input":"2023-08-25T06:31:07.105612Z","iopub.status.idle":"2023-08-25T06:31:07.121001Z","shell.execute_reply.started":"2023-08-25T06:31:07.105572Z","shell.execute_reply":"2023-08-25T06:31:07.119968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get all CV scores\ntree1_cv_results = make_results('decision tree cv', tree1, 'auc')\ntree1_cv_results","metadata":{"execution":{"iopub.status.busy":"2023-08-25T06:31:07.124291Z","iopub.execute_input":"2023-08-25T06:31:07.125134Z","iopub.status.idle":"2023-08-25T06:31:07.158588Z","shell.execute_reply.started":"2023-08-25T06:31:07.125073Z","shell.execute_reply":"2023-08-25T06:31:07.157058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<img style=\"float: left\" src=\"https://i.imgur.com/HVpiyd6.png[/img\" width=\"60\">\n<b style = \"font-family: Arial; font-size: 16px\">Results:</b><p style = \"font-family:Verdana; font-size:14px\">The classification report above shows that the decision tree results is slight;y below than the logistic regression model achieved a precision of 99.99%, recall of 99.97%, f1-score of 99.99%, and accuracy of 99.97%, and AUC 99.99%. The AUC shows a strong model.\n    </p> ","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n<img style=\"float: left\" src=\"https://i.postimg.cc/kXz8cFqC/005-Img-Yellow-Notes-Draft-1-20220819.png\" width=\"60\">\n<b style = \"font-family: Arial; font-size: 16px\">Note:</b><ol style = \"font-family:Verdana; font-size:14px\">\nDecision trees can be vulnerable to overfitting, and random forests avoid overfitting by incorporating multiple trees to make predictions. You could construct a random forest model next. The model may come up too good as we may required to conduct feature engineering.\n</div>","metadata":{}},{"cell_type":"code","source":"def conf_matrix_plot(model, x_data, y_data):\n    '''\n    Accepts as argument model object, X data (test or validate), and y data (test or validate). \n    Returns a plot of confusion matrix for predictions on y data.\n    ''' \n  \n    model_pred = model.predict(x_data)\n    cm = confusion_matrix(y_data, model_pred, labels=model.classes_)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                             display_labels=model.classes_)\n  \n    disp.plot(values_format='')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T06:31:07.161096Z","iopub.execute_input":"2023-08-25T06:31:07.161599Z","iopub.status.idle":"2023-08-25T06:31:07.170247Z","shell.execute_reply.started":"2023-08-25T06:31:07.161552Z","shell.execute_reply":"2023-08-25T06:31:07.168556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate confusion matrix\nconf_matrix_plot(tree1, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T06:31:07.172154Z","iopub.execute_input":"2023-08-25T06:31:07.172465Z","iopub.status.idle":"2023-08-25T06:31:07.545860Z","shell.execute_reply.started":"2023-08-25T06:31:07.172437Z","shell.execute_reply":"2023-08-25T06:31:07.544497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the tree\nplt.figure(figsize=(85,20))\nplot_tree(tree1.best_estimator_, max_depth=6, fontsize=14, feature_names=X.columns, \n          class_names={0:'stayed', 1:'left'}, filled=True)\nplt.savefig('tree1.png', dpi=400, bbox_inches = \"tight\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-25T06:31:07.547532Z","iopub.execute_input":"2023-08-25T06:31:07.547867Z","iopub.status.idle":"2023-08-25T06:31:28.327014Z","shell.execute_reply.started":"2023-08-25T06:31:07.547837Z","shell.execute_reply":"2023-08-25T06:31:28.325558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#tree1_importances = pd.DataFrame(tree1.best_estimator_.feature_importances_, columns=X.columns)\ntree1_importances = pd.DataFrame(tree1.best_estimator_.feature_importances_, columns=['gini_importance'], index=X.columns)\ntree1_importances = tree1_importances.sort_values(by='gini_importance', ascending=False)\n\n# Only extract the features with importances > 0\ntree1_importances = tree1_importances[tree1_importances['gini_importance'] != 0]\ntree1_importances","metadata":{"execution":{"iopub.status.busy":"2023-08-25T06:31:28.328801Z","iopub.execute_input":"2023-08-25T06:31:28.329368Z","iopub.status.idle":"2023-08-25T06:31:28.349588Z","shell.execute_reply.started":"2023-08-25T06:31:28.329330Z","shell.execute_reply":"2023-08-25T06:31:28.348521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(data=tree1_importances, x=\"gini_importance\", y=tree1_importances.index, orient='h')\nplt.title(\"Decision Tree: Feature Importances for Annual Membership\", fontsize=12)\nplt.ylabel(\"Feature\")\nplt.xlabel(\"Importance\")\nplt.savefig('tree1-importance.png', dpi=400, bbox_inches = \"tight\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T06:31:28.351443Z","iopub.execute_input":"2023-08-25T06:31:28.351815Z","iopub.status.idle":"2023-08-25T06:31:29.954804Z","shell.execute_reply.started":"2023-08-25T06:31:28.351782Z","shell.execute_reply":"2023-08-25T06:31:29.953425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<img style=\"float: left\" src=\"https://i.imgur.com/HVpiyd6.png[/img\" width=\"60\">\n<b style = \"font-family: Arial; font-size: 16px\">Results:</b><p style = \"font-family:Verdana; font-size:14px\">Compared to logistic regression, the decision tree model shows slightly have lower performance with features such as unknown gender, Gen X, distance, trips to destinations like WTC and China Town, and trips during the summer, as well as the remaining features visible in the figure above. This outcome contrasts significantly with the odds ratio observed in the logistic regression results.\n    </p> ","metadata":{}},{"cell_type":"markdown","source":"# Model 3: Random Forrest (1)","metadata":{}},{"cell_type":"code","source":"# Instantiate model\nrf = RandomForestClassifier(random_state=42)\n\n# Assign a dictionary of hyperparameters to search over\ncv_params = {'max_depth': [2,4, None], \n             'max_features': [1.0],\n             'max_samples': [0.7, 1.0],\n             'min_samples_leaf': [3,5,7],\n             'min_samples_split': [3,4,6],\n             'n_estimators': [300, 500],\n             }  \n\n# Assign a dictionary of scoring metrics to capture\nscoring = {'accuracy', 'precision', 'recall', 'f1', 'roc_auc'}\n\n# Instantiate GridSearch\nrf1 = GridSearchCV(rf, cv_params, scoring=scoring, cv=4, refit='roc_auc')","metadata":{"execution":{"iopub.status.busy":"2023-08-24T15:32:38.244109Z","iopub.execute_input":"2023-08-24T15:32:38.244502Z","iopub.status.idle":"2023-08-24T15:32:38.251756Z","shell.execute_reply.started":"2023-08-24T15:32:38.244473Z","shell.execute_reply":"2023-08-24T15:32:38.250434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nrf1.fit(X_tr, y_tr) # --> Wall time: ~5:36:14s","metadata":{"execution":{"iopub.status.busy":"2023-08-24T15:32:45.884429Z","iopub.execute_input":"2023-08-24T15:32:45.884832Z","iopub.status.idle":"2023-08-24T21:09:11.128319Z","shell.execute_reply.started":"2023-08-24T15:32:45.884800Z","shell.execute_reply":"2023-08-24T21:09:11.127229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a path to the folder where you want to save the model\npath = '/kaggle/working/'","metadata":{"execution":{"iopub.status.busy":"2023-08-25T09:37:09.070558Z","iopub.execute_input":"2023-08-25T09:37:09.071130Z","iopub.status.idle":"2023-08-25T09:37:09.077444Z","shell.execute_reply.started":"2023-08-25T09:37:09.071093Z","shell.execute_reply":"2023-08-25T09:37:09.076052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def write_pickle(path, model_object, save_as:str):\n    '''\n    In: \n        path:         path of folder where you want to save the pickle\n        model_object: a model you want to pickle\n        save_as:      filename for how you want to save the model\n\n    Out: A call to pickle the model in the folder indicated\n    '''    \n\n    with open(path + save_as + '.pickle', 'wb') as to_write:\n        pickle.dump(model_object, to_write)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T09:37:09.782702Z","iopub.execute_input":"2023-08-25T09:37:09.783580Z","iopub.status.idle":"2023-08-25T09:37:09.791135Z","shell.execute_reply.started":"2023-08-25T09:37:09.783527Z","shell.execute_reply":"2023-08-25T09:37:09.789813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_pickle(path, saved_model_name:str):\n    '''\n    In: \n        path:             path to folder where you want to read from\n        saved_model_name: filename of pickled model you want to read in\n\n    Out: \n        model: the pickled model \n    '''\n    with open(path + saved_model_name + '.pickle', 'rb') as to_read:\n        model = pickle.load(to_read)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-08-25T09:37:10.969045Z","iopub.execute_input":"2023-08-25T09:37:10.969512Z","iopub.status.idle":"2023-08-25T09:37:10.976283Z","shell.execute_reply.started":"2023-08-25T09:37:10.969478Z","shell.execute_reply":"2023-08-25T09:37:10.975139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Write pickle\nwrite_pickle(path, rf1, 'hr_rf1')","metadata":{"execution":{"iopub.status.busy":"2023-08-24T21:09:11.164258Z","iopub.execute_input":"2023-08-24T21:09:11.164860Z","iopub.status.idle":"2023-08-24T21:09:11.195443Z","shell.execute_reply.started":"2023-08-24T21:09:11.164822Z","shell.execute_reply":"2023-08-24T21:09:11.194601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read pickle\nrf1 = read_pickle(path, 'hr_rf1')","metadata":{"execution":{"iopub.status.busy":"2023-08-24T21:09:11.196828Z","iopub.execute_input":"2023-08-24T21:09:11.197173Z","iopub.status.idle":"2023-08-24T21:09:11.225201Z","shell.execute_reply.started":"2023-08-24T21:09:11.197139Z","shell.execute_reply":"2023-08-24T21:09:11.224230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check best AUC score on CV\nrf1.best_score_","metadata":{"execution":{"iopub.status.busy":"2023-08-24T21:09:11.226654Z","iopub.execute_input":"2023-08-24T21:09:11.227519Z","iopub.status.idle":"2023-08-24T21:09:11.234646Z","shell.execute_reply.started":"2023-08-24T21:09:11.227479Z","shell.execute_reply":"2023-08-24T21:09:11.233437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get all CV scores\nrf1_cv_results = make_results('random forest cv', rf1, 'auc')\nprint(tree1_cv_results)\nprint(rf1_cv_results)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T21:09:11.235895Z","iopub.execute_input":"2023-08-24T21:09:11.236256Z","iopub.status.idle":"2023-08-24T21:09:11.260687Z","shell.execute_reply.started":"2023-08-24T21:09:11.236221Z","shell.execute_reply":"2023-08-24T21:09:11.259479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_scores(model_name:str, model, X_test_data, y_test_data):\n    '''\n    Generate a table of test scores.\n\n    In: \n        model_name (string):  How you want your model to be named in the output table\n        model:                A fit GridSearchCV object\n        X_test_data:          numpy array of X_test data\n        y_test_data:          numpy array of y_test data\n\n    Out: pandas df of precision, recall, f1, accuracy, and AUC scores for your model\n    '''\n\n    preds = model.best_estimator_.predict(X_test_data)\n\n    auc = round(roc_auc_score(y_test_data, preds), 3)\n    accuracy = round(accuracy_score(y_test_data, preds), 3)\n    precision = round(precision_score(y_test_data, preds), 3)\n    recall = round(recall_score(y_test_data, preds), 3)\n    f1 = round(f1_score(y_test_data, preds), 3)\n\n    table = pd.DataFrame({'model': [model_name],\n                        'AUC': [auc],\n                        'precision': [precision], \n                        'recall': [recall],\n                        'f1': [f1],\n                        'accuracy': [accuracy]\n                        })\n  \n    return table","metadata":{"execution":{"iopub.status.busy":"2023-08-25T09:38:12.191954Z","iopub.execute_input":"2023-08-25T09:38:12.192471Z","iopub.status.idle":"2023-08-25T09:38:12.202064Z","shell.execute_reply.started":"2023-08-25T09:38:12.192434Z","shell.execute_reply":"2023-08-25T09:38:12.200790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the results on validation set for both models\ntree1_val_results = get_scores('decision tree1 val', tree1, X_val, y_val)\nrf1_val_results = get_scores('random forest1 val', rf1, X_val, y_val)\n\n# Concatenate validation scores into table\nall_val_results1 = [tree1_val_results, rf1_val_results]\nall_val_results1 = pd.concat(all_val_results1).sort_values(by='AUC', ascending=False)\nall_val_results1","metadata":{"execution":{"iopub.status.busy":"2023-08-24T21:09:11.275409Z","iopub.execute_input":"2023-08-24T21:09:11.276385Z","iopub.status.idle":"2023-08-24T21:09:12.215089Z","shell.execute_reply.started":"2023-08-24T21:09:11.276349Z","shell.execute_reply":"2023-08-24T21:09:12.214013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<img style=\"float: left\" src=\"https://i.imgur.com/HVpiyd6.png[/img\" width=\"60\">\n<b style = \"font-family: Arial; font-size: 16px\">Results:</b><p style = \"font-family:Verdana; font-size:14px\">On the validation, the results are slightly the same for AUC and recall, for precision, f1 and accuracy are lower than the decision tree.\n    </p> ","metadata":{}},{"cell_type":"code","source":"# Get predictions on test data\nrf1_test_scores = get_scores('random forest1 test', rf1, X_test, y_test)\nrf1_test_scores","metadata":{"execution":{"iopub.status.busy":"2023-08-24T21:09:12.216954Z","iopub.execute_input":"2023-08-24T21:09:12.217376Z","iopub.status.idle":"2023-08-24T21:09:13.075804Z","shell.execute_reply.started":"2023-08-24T21:09:12.217339Z","shell.execute_reply":"2023-08-24T21:09:13.074870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate array of values for confusion matrix\npreds = rf1.best_estimator_.predict(X_test)\ncm = confusion_matrix(y_test, preds, labels=rf1.classes_)\n\n# Plot confusion matrix\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                             display_labels=rf1.classes_)\ndisp.plot()","metadata":{"execution":{"iopub.status.busy":"2023-08-24T21:09:13.076940Z","iopub.execute_input":"2023-08-24T21:09:13.077874Z","iopub.status.idle":"2023-08-24T21:09:14.210458Z","shell.execute_reply.started":"2023-08-24T21:09:13.077842Z","shell.execute_reply":"2023-08-24T21:09:14.209104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get feature importances\nfeat_impt = rf1.best_estimator_.feature_importances_\n\n# Get indices of top 10 features\nind = np.argpartition(rf1.best_estimator_.feature_importances_, -10)[-10:]\n\n# Get column labels of top 10 features \nfeat = X.columns[ind]\n\n# Filter `feat_impt` to consist of top 10 feature importances\nfeat_impt = feat_impt[ind]\n\ny_df = pd.DataFrame({\"Feature\":feat,\"Importance\":feat_impt})\ny_sort_df = y_df.sort_values(\"Importance\")\nfig = plt.figure()\nax1 = fig.add_subplot(111)\n\ny_sort_df.plot(kind='barh',ax=ax1,x=\"Feature\",y=\"Importance\")\n\nax1.set_title(\"Random Forest: Feature Importances for Annual Membership\", fontsize=12)\nax1.set_ylabel(\"Feature\")\nax1.set_xlabel(\"Importance\")\nplt.savefig('rf1-importance.png', dpi=400, bbox_inches = \"tight\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-24T21:09:14.212124Z","iopub.execute_input":"2023-08-24T21:09:14.212478Z","iopub.status.idle":"2023-08-24T21:09:15.576261Z","shell.execute_reply.started":"2023-08-24T21:09:14.212448Z","shell.execute_reply":"2023-08-24T21:09:15.575201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<img style=\"float: left\" src=\"https://i.imgur.com/HVpiyd6.png[/img\" width=\"60\">\n<b style = \"font-family: Arial; font-size: 16px\">Results:</b><p style = \"font-family:Verdana; font-size:14px\">We have displayed the top 10 feature importance variables for the Random Forest model. Among these variables, the top 5 are unknown, Gen X, trip duration, departing from Greenpoint, and distance. It's important to note that the order and selection of variables vary among different models.\n</p> ","metadata":{}},{"cell_type":"markdown","source":"# Model 4: XGBoost (1)","metadata":{}},{"cell_type":"code","source":"# 1. Instantiate the XGBoost classifier\nxgb = XGBClassifier(objective='binary:logistic', random_state=42)  \n\n# 2. Create a dictionary of hyperparameters to tune\ncv_params = {'max_depth': [4,8,12], \n             'min_child_weight': [3, 5],\n             'learning_rate': [0.01, 0.1],\n             'n_estimators': [300, 500]\n             }   \n\n# 3. Define a dictionary of scoring metrics to capture\nscoring = {'accuracy', 'precision', 'recall', 'f1'}\n\n# 4. Instantiate the GridSearchCV object\nxgb_cv1 = GridSearchCV(xgb, cv_params, scoring=scoring, cv=4, refit='f1')","metadata":{"execution":{"iopub.status.busy":"2023-08-25T06:31:29.960063Z","iopub.execute_input":"2023-08-25T06:31:29.960542Z","iopub.status.idle":"2023-08-25T06:31:29.969512Z","shell.execute_reply.started":"2023-08-25T06:31:29.960503Z","shell.execute_reply":"2023-08-25T06:31:29.968097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# # avg. 10:35:10s\nxgb_cv1.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T06:31:29.971933Z","iopub.execute_input":"2023-08-25T06:31:29.972410Z","iopub.status.idle":"2023-08-25T09:14:41.000059Z","shell.execute_reply.started":"2023-08-25T06:31:29.972375Z","shell.execute_reply":"2023-08-25T09:14:40.998771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"write_pickle(path, xgb_cv1, 'hr_xgb_cv1')","metadata":{"execution":{"iopub.status.busy":"2023-08-25T09:37:42.669864Z","iopub.execute_input":"2023-08-25T09:37:42.670328Z","iopub.status.idle":"2023-08-25T09:37:42.687245Z","shell.execute_reply.started":"2023-08-25T09:37:42.670294Z","shell.execute_reply":"2023-08-25T09:37:42.685934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_cv1 = read_pickle(path, 'hr_xgb_cv1')","metadata":{"execution":{"iopub.status.busy":"2023-08-25T09:37:46.071743Z","iopub.execute_input":"2023-08-25T09:37:46.072427Z","iopub.status.idle":"2023-08-25T09:37:46.089911Z","shell.execute_reply.started":"2023-08-25T09:37:46.072390Z","shell.execute_reply":"2023-08-25T09:37:46.088327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Examine best score\nxgb_cv1.best_score_","metadata":{"execution":{"iopub.status.busy":"2023-08-25T09:37:46.585772Z","iopub.execute_input":"2023-08-25T09:37:46.586340Z","iopub.status.idle":"2023-08-25T09:37:46.594774Z","shell.execute_reply.started":"2023-08-25T09:37:46.586301Z","shell.execute_reply":"2023-08-25T09:37:46.593351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Examine best parameters\nxgb_cv1.best_params_","metadata":{"execution":{"iopub.status.busy":"2023-08-25T09:37:47.269916Z","iopub.execute_input":"2023-08-25T09:37:47.271082Z","iopub.status.idle":"2023-08-25T09:37:47.280227Z","shell.execute_reply.started":"2023-08-25T09:37:47.271033Z","shell.execute_reply":"2023-08-25T09:37:47.278549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Call 'make_results()' on the GridSearch object\n#xgb_cv1_results = make_results('XGBoost 1: f1', xgb_cv1, 'f1')\n#print(xgb_cv1_results)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T09:37:48.895553Z","iopub.execute_input":"2023-08-25T09:37:48.896035Z","iopub.status.idle":"2023-08-25T09:37:48.902379Z","shell.execute_reply.started":"2023-08-25T09:37:48.895998Z","shell.execute_reply":"2023-08-25T09:37:48.900697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get scores on test data\npreds = xgb_cv1.best_estimator_.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T09:37:52.773324Z","iopub.execute_input":"2023-08-25T09:37:52.774624Z","iopub.status.idle":"2023-08-25T09:37:53.028315Z","shell.execute_reply.started":"2023-08-25T09:37:52.774578Z","shell.execute_reply":"2023-08-25T09:37:53.027108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get scores on test data\nxgb_cv1_test_scores = get_scores('XGBoost 1: test',xgb_cv1, X_test, y_test)\nxgb_cv1_test_scores","metadata":{"execution":{"iopub.status.busy":"2023-08-25T09:38:19.869200Z","iopub.execute_input":"2023-08-25T09:38:19.869702Z","iopub.status.idle":"2023-08-25T09:38:20.063969Z","shell.execute_reply.started":"2023-08-25T09:38:19.869661Z","shell.execute_reply":"2023-08-25T09:38:20.062691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate array of values for confusion matrix\ncm = confusion_matrix(y_test, preds, labels=xgb_cv1.classes_)\n\n# Plot confusion matrix\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                             display_labels=xgb_cv1.classes_)\ndisp.plot();","metadata":{"execution":{"iopub.status.busy":"2023-08-25T09:38:20.677554Z","iopub.execute_input":"2023-08-25T09:38:20.678068Z","iopub.status.idle":"2023-08-25T09:38:21.075915Z","shell.execute_reply.started":"2023-08-25T09:38:20.678030Z","shell.execute_reply":"2023-08-25T09:38:21.074652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_importance(xgb_cv1.best_estimator_, max_num_features=10)\n\nplt.title(XG-Boost: Feature Importances for Annual Membership\", fontsize=12)\nplt.savefig('xgboost1-importance.png', dpi=400, bbox_inches = \"tight\")","metadata":{"execution":{"iopub.status.busy":"2023-08-25T09:54:40.815456Z","iopub.execute_input":"2023-08-25T09:54:40.815839Z","iopub.status.idle":"2023-08-25T09:54:41.994661Z","shell.execute_reply.started":"2023-08-25T09:54:40.815806Z","shell.execute_reply":"2023-08-25T09:54:41.993266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<img style=\"float: left\" src=\"https://i.imgur.com/HVpiyd6.png[/img\" width=\"60\">\n<b style = \"font-family: Arial; font-size: 16px\">Results:</b><p style = \"font-family:Verdana; font-size:14px\">We have displayed for XGBoost and Random forest having 10 feature importance variables, for XGBoost we have distance, trip duration, temparature, wind speed and unkonown sex among the top. We can see that the variables and its order are different among models.\n</p> ","metadata":{}},{"cell_type":"markdown","source":"# Add : KMeans (1) - Cluster\n\n#### Scaled data","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.preprocessing import StandardScaler","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:00:24.019057Z","iopub.execute_input":"2023-08-26T00:00:24.020409Z","iopub.status.idle":"2023-08-26T00:00:24.026133Z","shell.execute_reply.started":"2023-08-26T00:00:24.020356Z","shell.execute_reply":"2023-08-26T00:00:24.024648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scale the data\nX_scaled = StandardScaler().fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:00:25.524884Z","iopub.execute_input":"2023-08-26T00:00:25.525362Z","iopub.status.idle":"2023-08-26T00:00:26.230086Z","shell.execute_reply.started":"2023-08-26T00:00:25.525323Z","shell.execute_reply":"2023-08-26T00:00:26.228760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit K-means and evaluate inertia for different values of k.\n\n### YOUR CODE HERE ###\n\nnum_clusters = [i for i in range(2, 30)]\n\ndef kmeans_inertia(num_clusters, x_vals):\n    \"\"\"\n    Accepts as arguments list of ints and data array. \n    Fits a KMeans model where k = each value in the list of ints. \n    Returns each k-value's inertia appended to a list.\n    \"\"\"\n    inertia = []\n    for num in num_clusters:\n        kms = KMeans(n_clusters=num, random_state=42)\n        kms.fit(x_vals)\n        inertia.append(kms.inertia_)\n\n    return inertia","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:01:34.964458Z","iopub.execute_input":"2023-08-26T00:01:34.964868Z","iopub.status.idle":"2023-08-26T00:01:34.972612Z","shell.execute_reply.started":"2023-08-26T00:01:34.964836Z","shell.execute_reply":"2023-08-26T00:01:34.971223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Return a list of inertia for k=2 to 30.\n\n### YOUR CODE HERE ###\n\ninertia = kmeans_inertia(num_clusters, X_scaled)\ninertia","metadata":{"execution":{"iopub.status.busy":"2023-08-25T09:44:34.559174Z","iopub.execute_input":"2023-08-25T09:44:34.559680Z","iopub.status.idle":"2023-08-25T09:54:40.145022Z","shell.execute_reply.started":"2023-08-25T09:44:34.559640Z","shell.execute_reply":"2023-08-25T09:54:40.144055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Elbow Plot","metadata":{}},{"cell_type":"code","source":"# Create an elbow plot\nplt.figure(figsize=(12,6))\nplot = sns.lineplot(x=num_clusters, y=inertia, marker = 'o')\nplot.set_xlabel(\"Number of clusters\")\nplot.set_ylabel(\"Inertia\")","metadata":{"execution":{"iopub.status.busy":"2023-08-25T09:54:40.147566Z","iopub.execute_input":"2023-08-25T09:54:40.149118Z","iopub.status.idle":"2023-08-25T09:54:40.582845Z","shell.execute_reply.started":"2023-08-25T09:54:40.149064Z","shell.execute_reply":"2023-08-25T09:54:40.581372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Evaluate silhouette score\n\n<div style = \"font-family: Arial; font-size: 16px\">\nUnlike inertia, silhouette score doesn't have its own attribute that can be called on the model object. To get a silhouette score, we have to use the `silhouette_score()` function that we imported from `sklearn.metrics`. You must pass to it two required parameters: your training data and their assigned cluster labels.</div>","metadata":{}},{"cell_type":"code","source":"# Instantiate model\nkmeans25 = KMeans(n_clusters=28, random_state=42)\nkmeans25.fit(X_scaled)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T09:56:36.960746Z","iopub.execute_input":"2023-08-25T09:56:36.962216Z","iopub.status.idle":"2023-08-25T09:57:08.863175Z","shell.execute_reply.started":"2023-08-25T09:56:36.962175Z","shell.execute_reply":"2023-08-25T09:57:08.861892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get silhouette score for kmeans25 model\nkmeans25_sil_score = silhouette_score(X_scaled, kmeans25.labels_)\nkmeans25_sil_score","metadata":{"execution":{"iopub.status.busy":"2023-08-25T10:01:44.531077Z","iopub.execute_input":"2023-08-25T10:01:44.531719Z","iopub.status.idle":"2023-08-25T10:09:52.688726Z","shell.execute_reply.started":"2023-08-25T10:01:44.531677Z","shell.execute_reply":"2023-08-25T10:09:52.687183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def kmeans_sil(num_clusters, x_vals):\n    '''\n    Fits a KMeans model for different values of k.\n    Calculates a silhouette score for each k value\n\n    Args:\n        num_clusters: (list of ints)  - The different k values to try\n        x_vals:       (array)         - The training data\n\n    Returns: \n        sil_score:    (list)          - A list of silhouette scores, one for each \\\n                                      value of k\n    '''\n  \n    sil_score = []\n    for num in num_clusters:\n        kms = KMeans(n_clusters=num, random_state=42)\n        kms.fit(x_vals)\n        sil_score.append(silhouette_score(x_vals, kms.labels_))\n    \n    return sil_score","metadata":{"execution":{"iopub.status.busy":"2023-08-25T10:11:42.838515Z","iopub.execute_input":"2023-08-25T10:11:42.838957Z","iopub.status.idle":"2023-08-25T10:11:42.846084Z","shell.execute_reply.started":"2023-08-25T10:11:42.838924Z","shell.execute_reply":"2023-08-25T10:11:42.845051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate silhouette scores for k=2-30\nsil_score = kmeans_sil(num_clusters, X_scaled)\nsil_score","metadata":{"execution":{"iopub.status.busy":"2023-08-25T10:12:13.571926Z","iopub.execute_input":"2023-08-25T10:12:13.572395Z","iopub.status.idle":"2023-08-25T14:07:36.687069Z","shell.execute_reply.started":"2023-08-25T10:12:13.572357Z","shell.execute_reply":"2023-08-25T14:07:36.685764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a line plot of silhouette scores \nplot = sns.lineplot(x=num_clusters, y=sil_score, marker = 'o')\nplot.set_xlabel(\"# of clusters\")\nplot.set_ylabel(\"Silhouette Score\")","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:07:36.689441Z","iopub.execute_input":"2023-08-25T14:07:36.689812Z","iopub.status.idle":"2023-08-25T14:07:37.126168Z","shell.execute_reply.started":"2023-08-25T14:07:36.689771Z","shell.execute_reply":"2023-08-25T14:07:37.125002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<img style=\"float: left\" src=\"https://i.imgur.com/HVpiyd6.png[/img\" width=\"60\">\n<b style = \"font-family: Arial; font-size: 16px\">Results:</b><p style = \"font-family:Verdana; font-size:14px\">It looks that This plot indicates that the silhouette score is not closest to 1 but the highest is when our data is partitioned after clusters twenty three, it keeps on increasing. It confirms what we saw in the inertia analysis is hard to notice an elbow. \n</p> ","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n<img style=\"float: left\" src=\"https://i.postimg.cc/kXz8cFqC/005-Img-Yellow-Notes-Draft-1-20220819.png\" width=\"60\">\n<b style = \"font-family: Arial; font-size: 16px\">Note:</b><ol style = \"font-family:Verdana; font-size:14px\">\nThe high evaluation scores, may rise doubt. Unrealistic score may be resulted due to <b>overfitting and data leakage</b> as when you train the model using data it appears in the test data or it is not the expected data to give when the model actually deployed. This can caused unreplicated in production. \n<br><br>   \nScenario of possibilities to understand this model is required. By considering the data from the four models with the complete dataset, we observe a 100% accuracy across decision tree, random forest, and XGBoost models. Building upon the insights shared in part 2, we can further delve into the analysis of trip distances categorized as short, medium, and long distances. Regarding trip durations, we have introduced additional columns to account for overtime. In the future, we might consider incorporating another duration metric that reflects the permissible time during the day, potentially leading to the removal of the original trip duration column. Furthermore, we can consider creating columns that categorize areas based on factors such as subway access, residential nature, commercial activity, recreational facilities, Instagram-worthy spots, and tourist attractions.\n<br><br>\nNext, feature engineering will address this likelihood of data leakage. \n</div>","metadata":{}},{"cell_type":"code","source":"# Initialize variables to store silhouette scores and cluster labels\nsilhouette_scores = []\ncluster_labels = []\n\n# Loop through different k values and calculate silhouette score\nfor k in range(2, 30):\n    kmeans = KMeans(n_clusters=k)\n    labels = kmeans.fit_predict(X_scaled)\n    score = silhouette_score(X_scaled, labels)\n    silhouette_scores.append(score)\n    cluster_labels.append(labels)\n\n# Find the optimal k value based on silhouette score\noptimal_k = np.argmax(silhouette_scores) + 2  # +2 because range starts from 2\n\n# Fit KMeans model with optimal k\noptimal_kmeans = KMeans(n_clusters=optimal_k)\noptimal_labels = optimal_kmeans.fit_predict(X_scaled)\n\n# Create scatter plot for optimal k\nplt.figure(figsize=(10, 8))\nplt.scatter([x[0] for x in X_scaled], [x[1] for x in X_scaled], c=optimal_labels, cmap='rainbow', s=100, alpha=0.7)\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.title(f'KMeans Clustering (Optimal k={optimal_k})')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-26T02:35:03.453448Z","iopub.execute_input":"2023-08-26T02:35:03.453986Z","iopub.status.idle":"2023-08-26T06:29:28.761961Z","shell.execute_reply.started":"2023-08-26T02:35:03.453949Z","shell.execute_reply":"2023-08-26T06:29:28.760331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<hr>\n<table style=\"color:black;\n           display:fill;\n           border-colapse: colapse;\n           width: 100%;\n           border: 1px solid black;\n           border-collapse: collapse;\n           border-style: solid;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n            \n  <h3 style = \"text-align:center\">Table 2. Machine Learning Model Feature Importance </h3>\n  <tr>\n    <th>Logistic Regression</th>\n    <th>Random Forest</th>    \n    <th>XG Boost</th>\n  </tr>\n  <tr style = \"text-align:center\">\n      <td><img style= \"margin:auto\" src=\"https://i.imgur.com/RzhEuBt.png\" width = \"600\"></td>\n      <td><img style= \"margin:auto\" src=\"https://i.imgur.com/3c9lod9.png\" width = \"600\"></td>\n      <td><img style= \"margin:auto\" src=\"https://i.imgur.com/QcsCIgg.png\" width = \"600\"></td>\n  </tr>\n  </table>","metadata":{}},{"cell_type":"markdown","source":"<img style=\"float:left\" src=\"https://i.imgur.com/wpcEXQC.png\" width=\"50\"><div style = \"font-family: Arial; font-size: 16px\">\n    <h1>Execute</h1></div>\n\n# Conclussion\n<hr>\n\n<div class=\"alert alert-block alert-success\" style=\"font-family:verdana; font-size:14px\">\n\nLogistic Regression\n<br><br>\nThe logistic regression model achieved 100% (all weighted averages), and accuracy of 100%, on the test set which we need to be skeptical as there can be data leakage and overfitting as the data is imballance more than 85% towards the annual membership.\n<br><br>\nTree-based Machine Learning\n<br><br>\nThe result is similar to logistic regression. Here we decided to combine Random forest and XG Boost feature importance results.\n<br>    \nThe models and the feature importances extracted from them, along with the survey results, confirm that in order to encourage the acquisition of annual memberships, it is crucial to raise awareness about the health and safety benefits of biking among the younger generation. This should be done in correlation with emphasizing the significance of trip duration and distance.\n<br><br>\nTo acquire annual membership, the following recommendations could be presented to the stakeholders:\n<li>Establish initiatives for safe cycling, including safety training and education, distribution of safety equipment, and related endeavors.\n<li>Foster community partnerships and programs, such as bike ambassadors, youth and family engagement, grants for low-income individuals, etc.\n<li> Expand station or location within the top departure and destination neighborhoods particularly as displayed in the feature importance results. For instance, consider the departure stations in Greenpoint and Murray Hill, as well as the destination stations in Chinatown and the World Trade Center. Additionally, conduct an in-depth exploration of the unique attributes that define these prominent locations.\n<li>The growth observed in 2015 demonstrates a clear seasonality pattern, characterized by a gradual rise during the summer months, reaching its peak in September during the fall, and subsequently experiencing a gradual decline. This trend allows us to concentrate on medium to large maintenance activities during the slower seasons. These maintenance activities could include workshop repairs, strategic planning, or acquiring new assets. The execution of these maintenance efforts can be initiated after the winter period, just before the onset of the summer season when the number of riders is expected to rise. This is an opportune time to implement on-the-spot repairs as needed.   \n<li>Allocate resources for repair and maintenance on-site, with a particular focus on quality checks in top trip areas during off-peak hours and particularly warm season.\n<li>Hire both seasonal and permanent staff members who can actively engage with communities and contribute to the organization's objectives.\n<li>Implement marketing and promotional awareness campaigns, such as #Bike4Youth and bike health events, as well as prominently displaying the NYCHA residents rate $5 per month at stations.\n<br><br>\nNext Steps\n<br><br>\nScenario of possibilities to understand this model is required. By considering the data from the four models with the complete dataset, we observe a 100% accuracy across decision tree, random forest, and XGBoost models. Building upon the insights shared in part 2, we can further delve into the analysis of trip distances categorized as short, medium, and long distances. Regarding trip durations, we have introduced additional columns to account for overtime. In the future, we might consider incorporating another duration metric that reflects the permissible time during the day, potentially leading to the removal of the original trip duration column. Furthermore, we can consider creating columns that categorize areas based on factors such as subway access, residential nature, commercial activity, recreational facilities, Instagram-worthy spots, and tourist attractions. Also, we can distinct the bike id into e-bike and reg-bike columns. Moreover, leveraging Pareto data, we can stratify trips into quartiles: the top 25% as high trips, the middle 50% as medium trips, the subsequent 80% as low trips, and any beyond the 80% threshold as developmental trips.\n<br>\nAs also mentioned earlier, the availability of user IDs allows us to categorize bikers into distinct groups such as platinum, frequent, high, medium, and low bikers. <b>This approach underscores the importance of user ID tracking, enabling us to determine the precise number of registered members who actively engage with the bike-sharing service. This, in turn, aids us in determining the optimal allocation of bike investments based on the observed demand patterns. Furthermore, we can conduct surveys to gain insights by sampling from the members, determining whether it is the demand or supply side that requires attention and adjustments. </b> This approach unlocks further potential for feature refinement.\n<br><br>\nWe can also see the cluster from this model which k = 28.\n</div>","metadata":{}},{"cell_type":"code","source":"from IPython.display import display, HTML\n# Link HTML files for pages\noutput_file_01 = \"https://www.kaggle.com/code/wahyuardhitama/proj005-p01-nyc-citibike-20230731\"\noutput_file_02 = \"https://www.kaggle.com/code/wahyuardhitama/proj005-p02-nyc-citibike-20230802\"\n\n# Display links to the saved HTML files\ndisplay(HTML(f\"<p style='font-size: 18px;'>Back to <a href='{output_file_01}' target='_blank' style='font-size: 18px;'>P01 </a>or back to <a href='{output_file_02}' target='_blank' style='font-size: 18px;'>P02 </a></p>\"))","metadata":{"execution":{"iopub.status.busy":"2023-08-26T00:14:32.339686Z","iopub.execute_input":"2023-08-26T00:14:32.340098Z","iopub.status.idle":"2023-08-26T00:14:32.348601Z","shell.execute_reply.started":"2023-08-26T00:14:32.340064Z","shell.execute_reply":"2023-08-26T00:14:32.347373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}